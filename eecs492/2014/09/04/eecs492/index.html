<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Agents and Rationality &middot; Notes
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-146052-15', 'getpoole.com');
    ga('send', 'pageview');
  </script>

  <!-- LaTeX Support -->
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Notes
        </a>
      </h1>
      <p class="lead">Class notes for Nate Harada</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>
      <a class="sidebar-nav-item" href="about">About</a>
      <a class="sidebar-nav-item" href="http://blog.nateharada.com">Blog</a>

      <p></p>
      
          <a class="sidebar-nav-item" href="/categories/eecs492">EECS492</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs598">EECS598</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs584">EECS584</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs545">EECS545</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs586">EECS586</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs583">EECS583</a> 
      

    </nav>

    <p>&copy; 2015. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Agents and Rationality</h1>
  <span class="post-date">04 Sep 2014</span>
  <h2 id="agents">Agents</h2>
<p>An agent is anything that acts on its environment and perceives its environment. Sensing is required, so a windup toy isn’t an agent. Agents also must pursue a set of pre-specified goals.</p>

<p><strong>Percepts</strong> - The perceptual inputs at any time</p>

<p><strong>Percept sequence</strong> - The history of everything an agent has perceived</p>

<p>Agents actions can only depend on things it perceives. Note that this can include non-states such as a <em>lack</em> of a wall.</p>

<p><strong>Agent function</strong> - Maps percepts to actions, what we’ll focus on</p>

<p><strong>Agent program</strong> - Implementation</p>

<p>We must somehow evaluate an Agent’s behavior. The answer generally depends on the task environment. Since rationality depends on the agent’s capabilities, we can say a rational agent tries to maximize a performance measure with respect to its capabilities and prior knowledge.</p>

<p>Learning is considered a part of rationality - you must learn to be rational.</p>

<p>Exam note: Proper definition of rationality will be on the exam.</p>

<p>Rationality - For each possible percept sequence, a rational agent should select an action that is expected to maximize its performance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent has.</p>

<h2 id="task-environment">Task Environment</h2>
<p>Task environments have seven different properties.</p>

<h4 id="fully-vs-partially-observable">Fully vs Partially Observable</h4>
<p>Can an agent see everything in the environment? If fully observable, there’s no internal state needed because we can see everything.</p>

<h4 id="singe-agent-vs-multiagent">Singe Agent vs Multiagent</h4>
<p>Multiagent environments mean that an there is another agent that impacts you.</p>

<h4 id="deterministic-vs-stochastic">Deterministic vs Stochastic</h4>
<p>Deterministic means we can predict perfectly the state of the world. In practice almost every environment is stochastic.</p>

<h4 id="episodic-vs-sequential">Episodic vs Sequential</h4>
<p>Episodic results in independent events - previous action doesn’t impact the now.</p>

<h4 id="static-vs-dynamic">Static vs Dynamic</h4>
<p>Dynamic means that the environment changes <em>while</em> the agent is thinking. </p>

<h4 id="discrete-vs-continuous">Discrete vs Continuous</h4>
<p>Refers to the way time is handled. Straightforward, same idea as DSP or control theory. Interesting idea, chess is discrete, but chess with a clock is continuous.</p>

<h4 id="known-vs-unknown">Known vs Unknown</h4>
<p>A known environment means that the agent knows the rules of the environment going in.</p>

<h2 id="agent-structure">Agent Structure</h2>
<p>An agent consists of its architecture and program. </p>

<p>A few model types of agents:</p>

<p><strong>Stateless</strong> - Effects of time aren’t modeled</p>

<p><strong>Fixed Model</strong> - Designer provides model, contrast to <strong>learning model</strong> where the agent can adapt.</p>

<p>A few planning types of agents:</p>

<p><strong>Reflexive</strong> - Actions based on preprogrammed conditions</p>

<p><strong>Predictive</strong> - Actions based on potential effects</p>

<h4 id="table-driven-agent">Table-Driven Agent</h4>
<p>Agents choose actions based on states, explicit structure. This is based on percept sequences, which grows large quickly. Table driven <em>must</em> look at all states, including all past states.</p>

<h4 id="simple-reflex-agent">Simple-Reflex Agent</h4>
<p>Similar to table driven, but based on what we see <em>right now</em>. This is a quite simple structure, and in partially observable worlds we can’t make correct decisions.</p>

</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/eecs583/2015/11/11/">
            Classic Optimization
            <small>11 Nov 2015</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/eecs583/2015/10/14/eecs583/">
            Pin Paper
            <small>14 Oct 2015</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/eecs583/2015/10/12/">
            Paper Reviews 1 and 2
            <small>12 Oct 2015</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>

    </div>

  </body>
</html>
