<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Notes &middot; Class notes for Nate Harada
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-146052-15', 'getpoole.com');
    ga('send', 'pageview');
  </script>

  <!-- LaTeX Support -->
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Notes
        </a>
      </h1>
      <p class="lead">Class notes for Nate Harada</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>
      <a class="sidebar-nav-item" href="about">About</a>
      <a class="sidebar-nav-item" href="http://blog.nateharada.com">Blog</a>

      <p></p>
      
          <a class="sidebar-nav-item" href="/categories/eecs492">EECS492</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs598">EECS598</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs584">EECS584</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs545">EECS545</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs586">EECS586</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs583">EECS583</a> 
      

    </nav>

    <p>&copy; 2015. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/eecs586/2015/01/07/eecs586-intro/">
        Information
      </a>
    </h1>

    <span class="post-date">07 Jan 2015</span>

    <h2 id="algorithms">Algorithms</h2>

<p><strong>Instructor:</strong> Quentin Stout</p>

<p><strong>Term:</strong> Winter 2015</p>

<h3 id="school-description">School Description</h3>
<p>Design of algorithms for nonnumeric problems involving sorting, searching, scheduling, graph theory and geometry. Design techniques such as approximation, branch-and-bound, divide-and-conquer, dynamic programming, greed and randomization applied to polynomial and NP-hard problems. Analysis of time and space utilization.</p>

<h3 id="meets">Meets</h3>
<p>Monday/Wednesday 12:00pm - 1:30pm in EECS 1500</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/eecs586/2015/01/07/eecs586/">
        Introduction
      </a>
    </h1>

    <span class="post-date">07 Jan 2015</span>

    <h2 id="course-logistics">Course Logistics</h2>
<p>This class is more about design of algorithms than analysis, but many times you’ll need to prove you can’t do better. Median grade is a high B+, grading is based on homework and a final. Everything must be typed!</p>

<h2 id="introduction">Introduction</h2>
<p>Algorithms are as important as the hardware. Mostly in this class we’ll determine bounds on algorithms, for example via the intergral test. </p>

<p>Small o: f is an upper bound but not very good, generally little o isn’t very helpful.</p>

<h2 id="o-notation">O-notation</h2>
<p>There are a few ways to describe runtimes:</p>

<ul>
  <li><script type="math/tex">\Theta(n)</script>: Order of, gives high and low bounds</li>
  <li><script type="math/tex">O(n)</script>: Order most of, gives high bound</li>
  <li><script type="math/tex">\Omega(n)</script>: Order at least, gives low bound</li>
  <li><script type="math/tex">o(n)</script>: Order less than, generally gives less information, think of as &lt; instead of &lt;=</li>
  <li><script type="math/tex">\omega(n)</script>: Order greater than, same as small o</li>
</ul>

<h2 id="bestworstavg-case">Best/Worst/Avg Case</h2>
<p>Sequential search: something is holding data, we can only go sequentially, trying to find a value.</p>

<p>Suppose: </p>

<p>A(1:n) of some key type (=,&lt;,&gt;)
x of same key type</p>

<p>Is x in A?</p>

<h4 id="notation">Notation</h4>
<p>y cand z = if y false then false
            else z</p>

<p>Suppose we just search straightforward. Loop and look. What’s the runtime? </p>

<p>Best Case (Fastest)</p>

<p><script type="math/tex"> \Theta(1) </script>
if x present and A(1)=x</p>

<p>Worst Case (<strong>This is what we care about</strong>)</p>

<p><script type="math/tex"> \Theta(n) </script>
if x absent or
A(n)=x and x doesn’t appear sooner</p>

<p>Average Case</p>

<p>We don’t know without knowing more about the system! We need probability distributions or other known facts. 
If we suppose that prob(i) is the prob that first occurence of x is at i, and we suppose x is present, then we can say expected num of items examined is:</p>

<script type="math/tex; mode=display"> \sum_{i=1}^{n} i prob(i) </script>

<p>Time = <script type="math/tex">\Theta</script> (Num of items examined)</p>


  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/eecs545/2015/01/07/eecs545-intro/">
        Information
      </a>
    </h1>

    <span class="post-date">07 Jan 2015</span>

    <h2 id="machine-learning">Machine Learning</h2>
<p><strong>Instructor:</strong> Satinder Singh</p>

<p><strong>Term:</strong> Winter 2015</p>

<h3 id="school-description">School Description</h3>
<p>Survey of recent research on learning in artificial intelligence systems. Topics include learning based on examples, instructions, analogy, discovery, experimentation, observation, problem-solving and explanation. The cognitive aspects of learning will also be studied.</p>

<h3 id="meets">Meets</h3>
<p>Monday/Wednesday 10:30am - 12:00pm in GG Brown room 1504</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/eecs545/2015/01/07/eecs545/">
        Introduction
      </a>
    </h1>

    <span class="post-date">07 Jan 2015</span>

    <h2 id="class-logistics">Class logistics</h2>
<ul>
  <li>Bi-weekly homework assignments, in whatever language, potentially Kaggle competitions</li>
  <li>3 exams (fuck)</li>
  <li>Use eecs545staff@umich.edu for course related emails</li>
</ul>

<h2 id="about-this-course">About this course</h2>
<p>Satinder’s research is reinforcement learning, so we can expect heavier treatment in that area. We will not follow a particular textbook. This class does not require 492, but it <em>does</em> require linear algebra.</p>

<p>Projects are possible in lieu of final! Must have group members and must pass interim reports.</p>

<h2 id="learning">Learning</h2>
<p>Representation is key! The choice of representation can help or hurt. We must also be aware of underlying assumptions that we make, because we can’t learn without assuming something.</p>

<p>Given a set of inputs <script type="math/tex">x_1, x_2, .., x_n</script>, where <script type="math/tex">x_i = (x_{i1}, x_{i2}, .., x_{id})</script>, we want to learn a function that maps from <script type="math/tex">\vec x</script> into classes.</p>

<p>Important distinction: f is <strong>not</strong> a decision boundary, but yields a decision boundary.</p>

<p>Unsupervised vs Supervised learning, pretty straightforward at this point. Labels vs no labels. Etc.</p>

<h3 id="reinforcement-learning">Reinforcement Learning</h3>
<p>This is Satinder’s shit, listen up kids. </p>

<p>The goal of RL is to learn an <em>optimal policy</em> from experience. We want to do this over time and maximize the sum of payoffs over time. How do we deal with partial observability, etc? Will cover POMDP, MDP, other RL parts.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/eecs584/2014/12/02/eecs584/">
        Paper Review - CloudBurst: Highly Sensitive Read Mapping with MapReduce
      </a>
    </h1>

    <span class="post-date">02 Dec 2014</span>

    <p>In a surprising article for advanced databases, this paper presents a parallel DNA sequence alignment algorithm that can execute on MapReduce, providing a super-linear(!) speedup over serial alignment algorithms. DNA alignment is a computationally heavy task that’s required to compare genomes between different people or different animals. Because two people’s DNA is not exactly the same, lining up similar segments is a complex task. In some cases there may be errors from the sequencing, and other disparities that require a fuzzy algorithm to properly match sequences. The paper first describes the serial DNA matching algorithm used in most cases, and then expands on the current MapReduce paradigm as a refresher for the user. The algorithm is presented for MapReduce’s sequence alignment, and results are presented.</p>

<p>In a traditional DNA sequence matching algorithm, the algorithm attempts to align “seeds”, which are segments of the sequence that match perfectly. These seeds are then grown outwards, relaxing the similarity requirements as it goes. The parallel version of this algorithm also uses the “seed-and-extend” method. In this case, the mappers check for seed growth points, and then the reduces grow the seeds, checking to see if there is an appropriate amount of similarity between sequences. Thus, intuitively, the algorithm parallelizes sequence alignment by starting with possible seed matches and then running many possible matches in parallel until only the correct result remains. Most fascinatingly, this algorithm provides super-linear performance gains over the serial version. Moving from 1 to 24 cores results in a 30-fold speed increase, and moving from 1 to 96 cores results in over a 100-fold increase. This suggests that the algorithm may perform better than the state of the art even on a dual core machine. I would have liked to see a comparison of the algorithm running on one machine to a serial version. It’s amazing that the overhead of MapReduce doesn’t contribute much, and that the results are so extraordinary. </p>

<p>If this paper had a weakness, I would say that it doesn’t do a very good job of explaining the optimizations available to MapReduce. Perhaps using the various memory resident optimizations and locality aware features, the authors could achieve even better performance. While this would be beneficial for publishing, I think the simplicity of the technique as presented is quite powerful and will likely allow researchers to incorporate fast alignment with relatively little overhead and a small learning curve.</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page12">Older</a>
  
  
    
      <a class="pagination-item newer" href="/page10">Newer</a>
    
  
</div>
    </div>

  </body>
</html>
