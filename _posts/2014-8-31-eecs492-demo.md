---
layout: post
title: Expectation Maximization 
category: eecs492
---


We want to fit a bunch of distributions to a set of data. However this does not offer a closed form solution, we must solve it iteratively. We do this in two steps:

1. Expectation step
2. Maximization step

Let's introduce a k-dimensional random variable 'Z', which is a vector representing which underlying distribution the data point came first. Binary vector with one if that distribution generated the underlying data.

### EM Search:
1. Re-estimate the expected values of the hidden variables $$z_ij$$ given the current hypothesis $$\langle u_1 .. u_k \rangle$$.

2. Recalculate the maximum likelihood hypothesis of <u1..uk> using these expected values for the hidden variables.

### Example for $$k=2$$
* Initialize $$h = \langle u_1 .. u_k \rangle$$
* Until h converges
    * E Step: Calculate $$E[z_{ij}]$$ assuming h's holds
    * M Step: Calculate new ML-hyp $$h' = \langle u_1' .. u_k' \rangle$$ assume $$z_{ij}=E[z_{ij}]$$ from the E-step
      
**We can view this as k-means that allows soft membership in multiple classes**

