---
layout: post
title: 'Paper Review - CloudBurst: Highly Sensitive Read Mapping with MapReduce' 
category: eecs584
---
In a surprising article for advanced databases, this paper presents a parallel DNA sequence alignment algorithm that can execute on MapReduce, providing a super-linear(!) speedup over serial alignment algorithms. DNA alignment is a computationally heavy task that's required to compare genomes between different people or different animals. Because two people's DNA is not exactly the same, lining up similar segments is a complex task. In some cases there may be errors from the sequencing, and other disparities that require a fuzzy algorithm to properly match sequences. The paper first describes the serial DNA matching algorithm used in most cases, and then expands on the current MapReduce paradigm as a refresher for the user. The algorithm is presented for MapReduce's sequence alignment, and results are presented.

In a traditional DNA sequence matching algorithm, the algorithm attempts to align "seeds", which are segments of the sequence that match perfectly. These seeds are then grown outwards, relaxing the similarity requirements as it goes. The parallel version of this algorithm also uses the "seed-and-extend" method. In this case, the mappers check for seed growth points, and then the reduces grow the seeds, checking to see if there is an appropriate amount of similarity between sequences. Thus, intuitively, the algorithm parallelizes sequence alignment by starting with possible seed matches and then running many possible matches in parallel until only the correct result remains. Most fascinatingly, this algorithm provides super-linear performance gains over the serial version. Moving from 1 to 24 cores results in a 30-fold speed increase, and moving from 1 to 96 cores results in over a 100-fold increase. This suggests that the algorithm may perform better than the state of the art even on a dual core machine. I would have liked to see a comparison of the algorithm running on one machine to a serial version. It's amazing that the overhead of MapReduce doesn't contribute much, and that the results are so extraordinary. 

If this paper had a weakness, I would say that it doesn't do a very good job of explaining the optimizations available to MapReduce. Perhaps using the various memory resident optimizations and locality aware features, the authors could achieve even better performance. While this would be beneficial for publishing, I think the simplicity of the technique as presented is quite powerful and will likely allow researchers to incorporate fast alignment with relatively little overhead and a small learning curve.
