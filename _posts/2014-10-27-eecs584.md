---
layout: post
title: 'Paper Review - Authoritative Sources in a Hyperlinked Environment' 
category: eecs584
---
In the late 90s, the World Wide Web was quickly becoming a global internet, and research in characterizing the network's structure was coming to a head. While Google is generally credited for the creation of authority based search algorithm, on the other coast Professor Jon Kleinberg was developing an algorithm that formed the basis for Google and provided complex algorithmic representation of webpages. This paper outlines Kleinberg's "HITS" algorithm (which is actually never called HITS in the publication), which represents pages by both authority as well as a "hub score" which estimates how value that page is to others.

The issue of searching the web was the primary motivation of this paper, like many others at the time. This paper, unlike the PageRank paper, develops in depth mathematical description of its algorithm. The author represents the internet as a directed graph, and runs an iterated algorithm to develop its two scores. First, it tries to determine authority by inspecting how many hubs point to it. Second, it updates its hub score to be the sum of the authority scores it points to. The authors provide mathematical proof (based on eigenvector analysis) that the algorithm indeed converges. This is a contrast to the Google PageRank paper, which does not provide much mathematical rigor. 

One major weakness of this technique is that the rankings themselves are dependent on the search terms, meaning that a new ranking must be computed for each query that is given to the system. This makes the HITS algorithm weak for a search engine as the processing power required would be immense for large loads, especially back in the time period it was developed. It does, however, only use "relevant" documents which is good for increasing computation speed and is a strength as it doesn't require the entire database to compute. One could potentially see this being useful for a highly distributed algorithm - by partitioning data into disjoint subsets we would ideally be able to run many queries in parallel.

I think the most interesting part of this paper isn't the algorithm itself, but the historical perspective one can view it with. This algorithm, besides the obvious issue of being a per-query algorithm, is basically what Google ended up creating. Not to disparage Google's accomplishments, but most of the ideas here were used and tweaked by Google. This paper shows that history really is written by the winner, as it's conceivable that had Dr Kleinberg been an entrepreneur that Google would never have gained traction. In some ways the algorithm is superior - for example it computes both hub and authority rankings which would help in ranking and search. The paper especially is far superior, offering proofs of convergence as well as a comprehensive discussion of use cases and modifications possible. Fortunately for Google, however, this paper was never commercialized and PageRank ended up gaining fame as the "first" authority based search algorithm.
