---
layout: post
title: Online Learning 
category: 
---
## Online Learning
We want to learn as we get new data in the system. Generally we can use the multiarmed bandit problem to try and minimize regret, where at each point we select an arm. There exists a strategy where our regret is no worse than O(log n). The UCB algorithm says that you should choose the arm with the highest uncertainty and the highest reward. 
