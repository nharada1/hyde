---
layout: post
title: Continuous Probability 
category: eecs492
---
## More Bayesian Networks
Important types of networks:

#### Singly Connected Network
At most one undirected path between any node pair. Space and time complexity is linear in size of network.

#### Multiply Connected Network
Multiple undirected paths between nodes. Space and time complexity is exponential in size. If we identify a set of variables that will render a network singly connected we can split apart the network to create a singly connected network. We could also transform a network into a "polytree" where we join individual nodes to form cluster nodes. 

## Approximate Inference
Many times the network grows out of control, so we have to estimate. Our goal is to generate samples from a known distribution. **Direct sampling** is the easiest way to do this. We just sample many times and eventually get a close approximation to our real network. If our distribution is hard to sample, we can use **rejection sampling** to compute conditional probability. This method rejects samples that don't match the evidence. Instead of calculating the full joint probability, we only calculate the probability for specific relations. In rejection sampling, as your conditionals become more rare, accuracy rapidly falls. 

Is there a better way? Yes, we can use **liklihood weighting**. In this method, we only want to generate samples consistent with the evidence. We'll fix the values for evidence and sample only non-evidence variables. 

## Continuous Probability Distributions
Basics of continuous probability here: integrating under curve is 1, probability at exactly one point is zero, etc etc. In continuous probability, we use **expectation** to discuss a variable's value. 

$$ E[x] = \int_{- \infty}^{\infty} xP(x) dx $$

Expected value is average, but average only thinks of uniform distribution. Basic properties:

1. $$ E[\alpha] = \alpha $$
2. $$ E[\alpha x] = \alpha E[x] $$
3. $$ E[\alpha + x] = \alpha + E[x] $$
4. $$ E[x+y] = E[x] + E[y] $$

Expected value is a linear operator which is just peachy. However, expected values are not unique, we want a measure of how spread the data is:

$$ \begin{align*}
\sigma^2 &= E[(x-E[x])^2] \\
         &= E[x^2] - 2x(E[x]) + (E[x])^2 \\
         &= E[x^2] - (E[x])^2
   \end{align*}
$$ 

Also introducing a Guassian distribution. These are nice because we know the values based on variance and mean. It's also its own conjugate prior (it's the exponential distribution of the statistics world). Of course we can have multiple dimensions of random variables, which we can talk about via correlation. 
