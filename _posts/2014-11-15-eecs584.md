---
layout: post
title: 'Paper Review - RemusDB: Transparent High Availability for Database Systems' 
category: eecs584
---
Highly available database systems are becoming more important and companies and services trade-off consistancy for availability. This paper presents RemusDB, a software layer designed to introduce high availability in commodity database systems. It does this via virtual machine, placing the host database on a VM and replicating the VM to provide failover. This design allows any database to be used as the underlying system, freeing database designers from the complexities of high availiability. 

The Remus system is an established failover system for virtual machines that run on the Xen hypervisor. Remus checkpoints the VM at various times, capturing the complete state of the device. On the event of a failure, the client is forwarded to the new system, which has an exact (or near exact) copy of the old VM. Thus, the client sees no interruption of service and continues on like nothing happened. While a powerful tool, Remus presents problems when running a database system. Specifically, large amounts of memory must be maintained. Additionally, RemusDB reduces latency added to the client-server communication path by the failover mechanisms. The primary insight of this paper is the idea of compressing checkpoints to transfer less data during replication. Because databases generally maximize memory usage to provide faster performance via caching, this idea is important for database workloads. RemusDB also selectively ignores certain parts of memory that can be reconstructed by the backup machine, again reducing memory transfer. In theory this would make the failover slower, but the authors don't mention this at all.

The paper also changes the underlying network code to work around Remus' network buffering. Remus holds packets until a checkpoint is completed, potentially disrupting database service. While required for RemusDB to work, this part of the paper seems to me by far the weakest. The authors actually change the underlying database as well as the linux kernel itself to allow the DBMS to selectivly decide which packets can be buffered until the next checkpoint. While I understand the motivation behind this, it to me seems to defeat the entire purpose of RemusDB, which is to lie atop the hypervisor to provide availability. The authors claim that any DBMS should work with the system, but with this modification we will require a new "RemusDB approved" version of the DBMS to actually implement any of the systems. 

One final thing to note is that consistancy is still mostly achieved even though we have a highly available system. RemusDB is 2-safe, meaning that updates will not be lost in the event of a failover. This is possible because transaction commits are not acknowledged until both systems have recorded the update. One interesting discussion would be how this impacts the CAP theorem, as we must trade availability for consistency in some form.  
