---
layout: post
title: 'Paper Review - BlinkDB: Queries with Bounded Errors and Bounded Response Times on Very Large Data' 
category: eecs584
---
As data warehouses grow larger, the amount of time required to process queries begins to outpace the development of the hardware and software that runs the system. Ethernet links and hard-drives have limits on speed, and interactive queries become impossible in petabyte scale systems on commodity hardware. To remedy this, the authors of this paper propose a sampling based system. The core concept of BlinkDB is that by sampling the tables of a database, the system can return approximate answers to queries. These answers may not be exact, but should be close enough for many OLAP and data mining tasks. For example, if we wanted to calculate the average income of a town, we could sample the residents to get an approximate answer, which in many cases will be close enough. The paper also stresses the idea of error bounds for the returned results. This is important because a user wants to know how close their answer is to the true result. By returning error bounds the user can keep in mind the statistical consequences of their actions. 

BlinkDB is built atop two key ideas: a stratified sampling method and a dynamic sample selection strategy. The first important contribution is stratified sampling. Because the underlying samples may be inadequately distributed, BlinkDB maintains a set of stratified samples over the original data. Stratified sampling is the technique of sampling from different groups unequally in order to reduce bias. The authors do this because if some members of a subset are rare, we will be unable to construct accurate estimates over them if we sample indiscriminately. BlinkDB also introduces optimizations that allow the user to specify the latency or accuracy of a query in SQL. For example, a user can declare they would like results WITHIN 5 SECONDS or ERROR WITHIN 10% AT CONFIDENCE 95%. The paper outlines a method in which multiple samples are kept of the data, and the appropriate sample set is used to properly answer a query. Additionally, BlinkDB must keep an error latency profile of various queries in order to estimate the time cost of a query - the software uses both an error and latency profile for this. The system itself is built atop Spark and Hive, intercepting queries in the Shark driver to apply Hive UDAFs to the data. 

The strength of this paper lies in its stratified sampling method and the error latency profile used to estimate cost of a query. The results are promising, and sampling a database allows for interactive query sessions on databases that are otherwise too large. The system also is quite powerful because it's built atop Spark, a memory resident extension to the distributed computation ecosystem Hadoop. The paper does have some weaknesses not addressed in this revision. One major weakness is that the aggregate functions must assume a normally distributed super-sample because they rely on closed-form estimators. Later versions of the paper introduce a bootstrapping method to deal with non-parametric datasets. Unrelated to the paper, the actual code released by the project is quite poor, with few features implemented and many discrepancies to the original work. This makes it impossible to duplicate the results given in the paper.
