---
layout: post
title: Local Search 
category: eecs492
---
## Recap
We'll do a short recap. Maybe, but not likely short.

### Informed Search
Informed searches use data about the goal that we have that's not part of the problem definition. For example, **A-star** search uses a heuristic function to work towards a goal, and applies the node cost as *path cost + heuristic cost*.

Quick proof: Prove A-star is optimal. This will likely be on the exam.

First prove A-star is non-decreasing cost
Then argue about the exploration of the path cost

There are also memory bound heuristic searchs. **Iterative deepening** A-star is like iterative deepening but cutoff is now f_cost and not the depth. We can also use **recursive best first search** to mimic best first search but cutting memory by only storing one child.

Heuristics can be designed in several ways, one way is to relax the problem. For example, we can solve only part of the problem and create a pattern database with solutions to all the possible subproblems.

## Local Search
Previously we explored the search space in a systematic way. When a goal is found the path is the solution. In many cases we actually don't care about the path, the final product is important. During a local search, we evaluate and modify the current state.

Example - 8 queen problem. We only care that this is solved, not the path to the solution. 

In local search, we only maintain the current node, and we don't retain path. This allows us to solve both massive search space problems as well as pure optimization problems. Complete if we reach the goal always, optimal if we always in the local maximum.

### Hill Climbing
We just move in the direction of the gradient and try and find the nearest peak. This search is not globally optimal unless the objective function is convex. How can we hill climb with the 8 queen problem?

We'll define a heuristic that keeps track of how many queens conflict, and just go until we've hit zero, headed towards the minimum. In some cases we hit the local maximum though, and this isn't the solution. Classic optimization problem, but how to solve? We can offer stochastic solutions to hill climbing, which generally require many runs. Unfortunately this doesn't offer a worst case guarantee.

### Simulated Annealing
Allows a transition from one non-local state to another. Probability of this transition falls over time. We pick a random move, if it improves we accept it. If not, we either ignore it, or accept it with probability P. 

### Local Beam Search
We track k states instead of only one. Generate k initial states and generate successors for each state, saving only the best. This is basically a best first search that occurs in local space instead of global.

### Genetic Algorithm
We start with randomly generated states and rate each. Then we combine parents and randomly mutate some of them. The process repeats as we proceed, discarding agents with low fitness and keeping better ones. In genetic algorithms, the fitness function is quite important, similar to the heuristic in informed search. 
