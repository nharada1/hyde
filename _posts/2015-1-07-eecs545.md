---
layout: post
title: Introduction 
category: eecs545
---

## Class logistics
* Bi-weekly homework assignments, in whatever language, potentially Kaggle competitions
* 3 exams (fuck)
* Use eecs545staff@umich.edu for course related emails

## About this course
Satinder's research is reinforcement learning, so we can expect heavier treatment in that area. We will not follow a particular textbook. This class does not require 492, but it *does* require linear algebra.

Projects are possible in lieu of final! Must have group members and must pass interim reports.

## Learning
Representation is key! The choice of representation can help or hurt. We must also be aware of underlying assumptions that we make, because we can't learn without assuming something.

Given a set of inputs $$x_1, x_2, .., x_n$$, where $$x_i = (x_{i1}, x_{i2}, .., x_{id})$$, we want to learn a function that maps from $$\vec x$$ into classes.

Important distinction: f is **not** a decision boundary, but yields a decision boundary.

Unsupervised vs Supervised learning, pretty straightforward at this point. Labels vs no labels. Etc.

### Reinforcement Learning
This is Satinder's shit, listen up kids. 

The goal of RL is to learn an *optimal policy* from experience. We want to do this over time and maximize the sum of payoffs over time. How do we deal with partial observability, etc? Will cover POMDP, MDP, other RL parts.
