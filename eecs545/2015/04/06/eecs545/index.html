<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Markov Decision Processes &middot; Notes
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-146052-15', 'getpoole.com');
    ga('send', 'pageview');
  </script>

  <!-- LaTeX Support -->
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Notes
        </a>
      </h1>
      <p class="lead">Class notes for Nate Harada</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>
      <a class="sidebar-nav-item" href="about">About</a>
      <a class="sidebar-nav-item" href="http://blog.nateharada.com">Blog</a>

      <p></p>
      
          <a class="sidebar-nav-item" href="/categories/eecs492">EECS492</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs598">EECS598</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs584">EECS584</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs545">EECS545</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs586">EECS586</a> 
      
          <a class="sidebar-nav-item" href="/categories/eecs583">EECS583</a> 
      

    </nav>

    <p>&copy; 2015. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Markov Decision Processes</h1>
  <span class="post-date">06 Apr 2015</span>
  <h2 id="markov-process">Markov Process</h2>
<p>At each time step we get a reward from our action. Consider the problem in the book found <a href="http://webdocs.cs.ualberta.ca/~sutton/book/ebook/node33.html">here</a>. Transitions are random, so even without noise in the reward there is an expected value. The optimal policy is simultaneously optimal for every state, although the optimal policy may not be unique. As a Markov problem, the probabilities don’t change over time, so the value function <em>is a function of just state</em>. </p>

<h2 id="problems">Problems</h2>
<p>We start with a given policy and want to compute how good it is. Optimal control problem is find the optimal policy. Today will cover policy evaluation.</p>

<h2 id="policy-evaluation">Policy Evaluation</h2>
<p>Implementation note: to construct a policy matrix, take a row from each matrix of actions corresponding to the policy we are given. Given a pi, how do we find a Vpi? </p>

<p>First option: Monte Carlo approach. Just sample a ton of times. We’ll stop early because eventually the discount factor creates a vanishing function.
Second option: Matrix inversion method. Requires a model. Uses the value equation and solves.
Third option: Iterative approach. Same as previous, but we solve recursively.</p>

<p>Why Monte Carlo?</p>

</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/eecs583/2015/11/11/">
            Classic Optimization
            <small>11 Nov 2015</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/eecs583/2015/10/14/eecs583/">
            Pin Paper
            <small>14 Oct 2015</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/eecs583/2015/10/12/">
            Paper Reviews 1 and 2
            <small>12 Oct 2015</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>

    </div>

  </body>
</html>
